[{"path":"https://camaradesuk.github.io/ASySD/articles/basic-deduplication.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Simple Deduplication","text":"First, install load ASySD package.","code":"# devtools::install_github(\"camaradesuk/ASySD\") library(ASySD)"},{"path":"https://camaradesuk.github.io/ASySD/articles/basic-deduplication.html","id":"loading-citation-data","dir":"Articles","previous_headings":"","what":"Loading Citation Data","title":"Simple Deduplication","text":"Begin loading citation data Endnote XML file using load_search() function. can specify alternative file formats CSV, RIS, BIB needed.","code":"citations <- load_search(\"systematic_search.xml\", method=\"endnote\")"},{"path":"https://camaradesuk.github.io/ASySD/articles/basic-deduplication.html","id":"automated-deduplication","dir":"Articles","previous_headings":"","what":"Automated deduplication","title":"Simple Deduplication","text":"Remove duplicate citations automatically using dedup_citations function. dedup_citations function returns list two dataframes default. first contains unique citations duplicates removed automatically ASySD. cases, remove vast majority duplicates. likely duplicates remaining need manual review human (see next step).","code":"results <- dedup_citations(citations, merge_citations = TRUE) #> formatting data... #> identifying potential duplicates... #> identified duplicates! #> flagging potential pairs for manual dedup... #> Joining with `by = join_by(duplicate_id.x, duplicate_id.y)` #> 8948 citations loaded... #> 3508 duplicate citations removed... #> 5440 unique citations remaining! unique_citations <- results$unique"},{"path":"https://camaradesuk.github.io/ASySD/articles/basic-deduplication.html","id":"manual-deduplication","dir":"Articles","previous_headings":"","what":"Manual deduplication","title":"Simple Deduplication","text":"Review pairs using manual_dedup_shiny() function. opens interactive shiny app allow go potential duplicate pair determine whether represents true duplicate (press 1) (press 3). Save output object can use next step. True duplicates “match” result column. Non duplicates “match” result column.","code":"post_manual_review <- manual_dedup_shiny(potential_duplicates)"},{"path":"https://camaradesuk.github.io/ASySD/articles/basic-deduplication.html","id":"final-deduplication","dir":"Articles","previous_headings":"","what":"Final Deduplication","title":"Simple Deduplication","text":"Combine results automated manual deduplication using dedup_citations_add_manual() function. Include results manual deduplication using additional_pairs argument. rows result column = “match” considered ASySD additional duplicates.","code":"final_results <- dedup_citations_add_manual(unique_citations,additional_pairs = post_manual_review)"},{"path":"https://camaradesuk.github.io/ASySD/articles/basic-deduplication.html","id":"exporting-results","dir":"Articles","previous_headings":"","what":"Exporting Results","title":"Simple Deduplication","text":"can now write results file import reference manager systematic review software","code":"write_citations(final_results, type=\"txt\", filename=\"citations.txt\")"},{"path":"https://camaradesuk.github.io/ASySD/articles/large-dedup.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Deduplicating large datasets","text":"First, install load ASySD package.","code":"# devtools::install_github(\"camaradesuk/ASySD\") library(ASySD)"},{"path":"https://camaradesuk.github.io/ASySD/articles/large-dedup.html","id":"loading-data","dir":"Articles","previous_headings":"","what":"Loading data","title":"Deduplicating large datasets","text":"First, load citations Endnote XML file using load_search() function. Alternatively, can upload file types .csv files changing method argument.","code":"citations <- load_search(\"systematic_search.xml\", method=\"endnote\")"},{"path":"https://camaradesuk.github.io/ASySD/articles/large-dedup.html","id":"batch-deduplication","dir":"Articles","previous_headings":"","what":"Batch deduplication","title":"Deduplicating large datasets","text":"handle large datasets effectively, recommend running deduplication batches. approach especially useful datasets 100,000 records. Set batch_n parameter control batch size, default value 50,000. , illustrate batching smaller scale demonstration purposes.","code":"results <- batch_dedup(citations, batch_n=2000, sort_by = c(\"year\", \"title\",\"author\")) #> Splitting up dataframe #> batch 1 complete ✔ #> batch 2 complete ✔ #> batch 3 complete ✔ #> batch 4 complete ✔ #> batch 5 complete ✔ #> identified 5457 unique citations"},{"path":"https://camaradesuk.github.io/ASySD/articles/large-dedup.html","id":"additional-rounds-of-duplication","dir":"Articles","previous_headings":"","what":"Additional rounds of duplication","title":"Deduplicating large datasets","text":"initial deduplication, refinement may necessary. Duplicates may separated different batches example - years differ substantially one year missing. can perform additional rounds deduplication using different sorting criteria, title alone. Using results first round deduplication input, can run batch deduplication check results. instance, running identified 3 additional duplicates.","code":"# get unique results from round 1 unique_r1 <- results$unique  # deduplicate again using unique results, setting different sort criteria results_r2 <- batch_dedup(unique_r1, batch_n=2000, sort_by = c(\"title\")) #> Splitting up dataframe #> batch 1 complete ✔ #> batch 2 complete ✔ #> batch 3 complete ✔ #> identified 5454 unique citations  # get results after 2 rounds of deduplication unique_r2 <- results_r2$unique"},{"path":"https://camaradesuk.github.io/ASySD/articles/large-dedup.html","id":"exporting-results","dir":"Articles","previous_headings":"","what":"Exporting results","title":"Deduplicating large datasets","text":"deduplication complete, can export unique records file import reference managers systematic review software.","code":"write_citations(unique_r2, type=\"txt\", filename=\"unique.txt\")"},{"path":"https://camaradesuk.github.io/ASySD/articles/search-updates.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Updating a Systematic Search","text":"First, install load ASySD package.","code":"# devtools::install_github(\"camaradesuk/ASySD\")library(ASySD) library(ASySD)"},{"path":"https://camaradesuk.github.io/ASySD/articles/search-updates.html","id":"loading-citation-data","dir":"Articles","previous_headings":"","what":"Loading citation data","title":"Updating a Systematic Search","text":"Load citations existing search file using load_search() function. example, use csv format. Load citations new systematic search.","code":"existing_search <- load_search(\"old_sr_search.csv\") new_search <- load_search(\"new_sr_search.csv\")"},{"path":"https://camaradesuk.github.io/ASySD/articles/search-updates.html","id":"combine-old-and-new-citation-data","dir":"Articles","previous_headings":"Loading citation data","what":"Combine old and new citation data","title":"Updating a Systematic Search","text":"deduplication, must bind citations one dataframe. First, give search different source can specify citations retain.","code":"existing_search$source <- \"old\" new_search$source <- \"new\"  all_citations <- plyr::rbind.fill(existing_search, new_search)"},{"path":"https://camaradesuk.github.io/ASySD/articles/search-updates.html","id":"automated-deduplication","dir":"Articles","previous_headings":"","what":"Automated deduplication","title":"Updating a Systematic Search","text":"Remove duplicate citations automatically using dedup_citations function. specified argument merge=TRUE indicate want merge duplicate records record citations merged one. specified keep_source argument wish preferentially retain old citations. practice, means duplicate_id chosen set records preferentially record_id citation OLD systematic search. facilitate easy record linkage - see later. dedup_citations function returns list two dataframes default. first contains unique citations duplicates removed automatically ASySD. cases, remove vast majority duplicates. likely duplicates remaining need manual review human (see next step).","code":"results <- dedup_citations(all_citations, merge_citations = TRUE, keep_source = \"old\") #> formatting data... #> identifying potential duplicates... #> identified duplicates! #> flagging potential pairs for manual dedup... #> Joining with `by = join_by(duplicate_id.x, duplicate_id.y)` #> 8972 citations loaded... #> 472 duplicate citations removed... #> 8500 unique citations remaining! unique_citations <- results$unique"},{"path":"https://camaradesuk.github.io/ASySD/articles/search-updates.html","id":"manual-deduplication","dir":"Articles","previous_headings":"","what":"Manual deduplication","title":"Updating a Systematic Search","text":"check additional duplicates, get dataframe citations manual review. can review within R export csv / excel file go row pairs. reviewing pairs, create dataframe contianing true duplicate pairs. , suggested duplicates look like REAL duplicates. Alternatively, go one--one using manual_dedup_shiny() function. Now, get final deduplication results, use dedup_citations_add_manual()function. account additional duplicates reviewed, add additional_pairs argument.","code":"potential_duplicates <- results$manual_dedup true_duplicates <- potential_duplicates final_results <- dedup_citations_add_manual(unique_citations, additional_pairs = true_duplicates, merge_citations = TRUE, keep_source = \"old\") #> Joining with `by = join_by(record_id)`"},{"path":"https://camaradesuk.github.io/ASySD/articles/search-updates.html","id":"find-new-citations-identified-in-update","dir":"Articles","previous_headings":"","what":"Find new citations identified in update","title":"Updating a Systematic Search","text":"Now final set unique citations, can find new citations added latest systematic search? Lets also look citations identified searches removing citations single source. keep good records, don’t want lose track identifiers studies already included review. specifying citation keep important! illustrate , look specifically citations present old search. can check duplicate ids refer original record id existing_citations dataframe imported. can see, present. record_ids column can see different record_ids merged single citation. case make mistake don’t specify record_id keep duplicate_id, can use trace back citations original dataframes.","code":"library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union new_citations <- final_results %>%   filter(source == \"new\")   new_citations %>%    tail(3) %>%    gt::gt() %>%    gt::cols_hide(c(abstract)) crossover <- final_results %>%   filter(!source == \"new\") %>%   filter(!source == \"old\")   crossover %>%    tail(3) %>%    gt::gt() %>%    gt::cols_hide(c(abstract)) old_citations <- final_results %>%   filter(grepl(\"old\", source)) # find all citations in old search old_citations_check <- old_citations %>%   filter(duplicate_id %in% existing_search$record_id) #check that all citations use the OLD record_id as the duplicate_id  crossover %>%    tail(3) %>%    gt::gt() %>%    gt::cols_hide(c(abstract))"},{"path":"https://camaradesuk.github.io/ASySD/articles/search-updates.html","id":"exporting-results","dir":"Articles","previous_headings":"","what":"Exporting results","title":"Updating a Systematic Search","text":"deduplication complete, can export new unique records file import reference managers systematic review software.","code":"write_citations(new_citations, type=\"txt\", filename=\"unique.txt\")"},{"path":"https://camaradesuk.github.io/ASySD/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kaitlyn Hair. Author, maintainer, copyright holder. Lukas Wallrich. Author.","code":""},{"path":"https://camaradesuk.github.io/ASySD/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kaitlyn Hair, Zsanett Bahor, Malcolm Macleod,            Jing Liao, Emily S. Sena. (2021) Automated Systematic Search Deduplicator (ASySD):                  rapid, open-source, interoperable tool remove                  duplicate citations biomedical systematic reviews. bioRxiv. DOI 10.1101/2021.05.04.442412","code":"@Article{,   title = {The Automated Systematic Search Deduplicator (ASySD): a rapid, open-source,          interoperable tool to remove duplicate citations in biomedical systematic reviews.},   author = {Kaitlyn Hair and Zsanett Bahor and Malcolm Macleod and Jing Liao and Emily S Sena},   journal = {bioRxiv},   publisher = {Cold Spring Harbor Laboratory},   year = {2021},   doi = {10.1101/2021.05.04.442412}, }"},{"path":"https://camaradesuk.github.io/ASySD/index.html","id":"automated-systematic-search-deduplicator-asysd-","dir":"","previous_headings":"","what":"Automated Citation Deduplication","title":"Automated Citation Deduplication","text":"Removing duplicate references obtained different databases essential step conducting updating systematic literature reviews. ASySD (pronounced “assist”) tool automatically identify remove duplicate records.","code":""},{"path":"https://camaradesuk.github.io/ASySD/index.html","id":"shiny-application","dir":"","previous_headings":"","what":"Shiny application","title":"Automated Citation Deduplication","text":"tool available R package user-friendly shiny application.","code":""},{"path":"https://camaradesuk.github.io/ASySD/index.html","id":"tutorial","dir":"","previous_headings":"","what":"Tutorial","title":"Automated Citation Deduplication","text":"Please check new ASySD tutorial youtube. like extend huge thank ESMARConf giving us platform showcase ASySD within evidence synthesis community!","code":""},{"path":"https://camaradesuk.github.io/ASySD/index.html","id":"tool-performance","dir":"","previous_headings":"","what":"Tool performance","title":"Automated Citation Deduplication","text":"evaluation ASySD’s performance versus automated deduplication tools available ","code":""},{"path":"https://camaradesuk.github.io/ASySD/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation:","title":"Automated Citation Deduplication","text":"{r} install.packages(\"devtools\") devtools::install_github(\"camaradesuk/ASySD\")","code":""},{"path":"https://camaradesuk.github.io/ASySD/index.html","id":"requirements","dir":"","previous_headings":"","what":"Requirements","title":"Automated Citation Deduplication","text":"loading ASySD package functions, required fields automatically created based input data. metadata columns missing, automatically created ASySD set NA. optimal performance, recommend much metadata possible. using dataframe, ideally following column names:","code":""},{"path":"https://camaradesuk.github.io/ASySD/index.html","id":"automatically-deduplicate-citation-data","dir":"","previous_headings":"","what":"Automatically deduplicate citation data","title":"Automated Citation Deduplication","text":"```{r} # load citations citation_data <- load_search(filepath, method=“endnote”)","code":""},{"path":"https://camaradesuk.github.io/ASySD/index.html","id":"deduplicate","dir":"","previous_headings":"","what":"deduplicate","title":"Automated Citation Deduplication","text":"dedup_citations <- dedup_citations(citation_data)","code":""},{"path":"https://camaradesuk.github.io/ASySD/index.html","id":"get-unique-citation-dataframe","dir":"","previous_headings":"","what":"get unique citation dataframe","title":"Automated Citation Deduplication","text":"unique_citations <- dedup_citations$unique ```","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/ASySD-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ASySD: Automated Citation Deduplication — ASySD-package","title":"ASySD: Automated Citation Deduplication — ASySD-package","text":"Automated Systematic Search Deduplicator ('ASySD') includes functions automatically detect remove duplicate citations literature searches. details, see paper \"Automated Systematic Search Deduplicator (ASySD): rapid, open-source, interoperable tool remove duplicate citations biomedical systematic reviews. Hair K / Bahor Z / Macleod M / Liao J / Sena E (2023) doi:10.1186/s12915-023-01686-z .","code":""},{"path":[]},{"path":"https://camaradesuk.github.io/ASySD/reference/ASySD-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ASySD: Automated Citation Deduplication — ASySD-package","text":"Maintainer: Kaitlyn Hair kaitlyn.hair@ed.ac.uk (ORCID) [copyright holder] Authors: Lukas Wallrich lukas.wallrich@gmail.com (ORCID)","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/batch_dedup.html","id":null,"dir":"Reference","previous_headings":"","what":"Batch deduplication for large searches — batch_dedup","title":"Batch deduplication for large searches — batch_dedup","text":"function splits citations batches, deduplicates batch, binds results together one dataframe unique citations.","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/batch_dedup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Batch deduplication for large searches — batch_dedup","text":"","code":"batch_dedup(   citations,   batch_n = 50000,   keep_source = NULL,   keep_label = NULL,   sort_by = c(\"year\", \"title\", \"author\") )"},{"path":"https://camaradesuk.github.io/ASySD/reference/batch_dedup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Batch deduplication for large searches — batch_dedup","text":"citations dataframe containing citation information. batch_n Numeric value specifying maximum number citations per batch. Default 50000. keep_source Character vector specifying citation source(s) preferentially retain dataset unique record. keep_label Character vector specifying citation label(s) preferentially retain dataset unique record. sort_by Character vector specifying sorting criteria. Default c(\"year\", \"title\",\"author\"). Valid options column names citations dataframe.","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/batch_dedup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Batch deduplication for large searches — batch_dedup","text":"list components: unique - dataframe containing unique citations. manual_dedup - dataframe containing citations manually checked duplicates.","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/batch_dedup.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Batch deduplication for large searches — batch_dedup","text":"following fields used citations (provided): record_id, author, year, journal, doi, title, pages, volume, number, abstract, isbn, label, source","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/batch_dedup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Batch deduplication for large searches — batch_dedup","text":"","code":"# Perform batch deduplication result <- batch_dedup(citations_df, batch_n = 250) #> Splitting up dataframe #> batch 1 complete ✔ #> batch 2 complete ✔ #> batch 3 complete ✔ #> batch 4 complete ✔ #> batch 5 complete ✔ #> identified 611 unique citations  # View unique citations head(result$unique) #> # A tibble: 6 × 16 #>   duplicate_id author     year  journal doi   title pages volume number abstract #>   <chr>        <chr>      <chr> <chr>   <chr> <chr> <chr> <chr>  <chr>  <chr>    #> 1 1075         Doenst T.… 1996  Am J P… 10.1… Fast… H160… 270    5 Pt 2 We test… #> 2 1092         Dorheim T… 1991  Surgery NA    Enha… 136-… 110    2      Reversi… #> 3 1182         Erikson J… 1996  Am Hea… 10.1… Endo… 84-90 132    1 Pt 1 This st… #> 4 1184         Eskildsen… 1996  Ann N … 10.1… Expl… 210-… 793    NA     NA       #> 5 1210         Faris B.,… 1997  Ann Th… 10.1… Fail… 1735… 64     6      BACKGRO… #> 6 1211         Fatehi-Ha… 1997  Eur J … 10.1… Geni… 67-70 338    1      The pos… #> # ℹ 6 more variables: isbn <chr>, secondary_title <chr>, label <chr>, #> #   url <chr>, source <chr>, record_ids <chr>"},{"path":"https://camaradesuk.github.io/ASySD/reference/citations_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Exmaple citation data — citations_df","title":"Exmaple citation data — citations_df","text":"Exmaple citation data","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/citations_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exmaple citation data — citations_df","text":"","code":"citations_df"},{"path":"https://camaradesuk.github.io/ASySD/reference/citations_df.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Exmaple citation data — citations_df","text":"object class data.frame 1001 rows 15 columns.","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/dedup_citations.html","id":null,"dir":"Reference","previous_headings":"","what":"This function deduplicates citation data — dedup_citations","title":"This function deduplicates citation data — dedup_citations","text":"function deduplicates citation data","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/dedup_citations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function deduplicates citation data — dedup_citations","text":"","code":"dedup_citations(   raw_citations,   manual_dedup = TRUE,   merge_citations = TRUE,   keep_source = NULL,   keep_label = NULL,   extra_merge_fields = NULL,   show_unknown_tags = TRUE,   user_input = NA )"},{"path":"https://camaradesuk.github.io/ASySD/reference/dedup_citations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function deduplicates citation data — dedup_citations","text":"raw_citations dataframe containing duplicate ciations manual_dedup Logical value. want retrieve dataframe manual deduplication? merge_citations Logical value. want merge matching citations? keep_source Character vector. Selected citation source preferentially retain dataset unique record keep_label Selected citation label preferentially retain dataset unique record extra_merge_fields Add additional fields merge, output similar label, source, record_id columns commas merged value show_unknown_tags label, source, merged field missing, want show \"unknown\"? user_input want proceed important columns missing? 1-yes; 2-","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/dedup_citations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"This function deduplicates citation data — dedup_citations","text":"list 2 dataframes - unique citations citations manually deduplicated option selected","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/dedup_citations.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"This function deduplicates citation data — dedup_citations","text":"following fields used raw_citations (provided): record_id, author, year, journal, doi, title, pages, volume, number, abstract, isbn, label, source","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/dedup_citations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"This function deduplicates citation data — dedup_citations","text":"","code":"# Perform deduplication result <- dedup_citations(citations_df, keep_source=\"Embase\") #> formatting data... #> identifying potential duplicates... #> identified duplicates! #> flagging potential pairs for manual dedup... #> Joining with `by = join_by(duplicate_id.x, duplicate_id.y)` #> 1001 citations loaded... #> 392 duplicate citations removed... #> 609 unique citations remaining!  # View unique citations head(result$unique) #> # A tibble: 6 × 16 #>   duplicate_id author     year  journal doi   title pages volume number abstract #>   <chr>        <chr>      <chr> <chr>   <chr> <chr> <chr> <chr>  <chr>  <chr>    #> 1 1018         Della-Mor… 2012  Pharma… 10.2… Gene… 1741… 13     15     A subth… #> 2 1107         Downey J.… 2008  Expert… 10.1… Free… 589-… 6      5      NA       #> 3 1127         Duan D. Y… 2005  Acta P… 10.1… Func… 265-… 26     3      In comp… #> 4 1184         Eskildsen… 1996  Ann N … 10.1… Expl… 210-… 793    NA     NA       #> 5 1288         Fryer R. … 2001  Am J P… 10.1… Esse… H134… 280    3      Stimula… #> 6 1290         Fryer R. … 2001  Basic … 10.1… ERK … 136-… 96     2      Opioids… #> # ℹ 6 more variables: isbn <chr>, secondary_title <chr>, label <chr>, #> #   url <chr>, source <chr>, record_ids <chr>"},{"path":"https://camaradesuk.github.io/ASySD/reference/dedup_citations_add_manual.html","id":null,"dir":"Reference","previous_headings":"","what":"This function performs additional deduplication with the additional of manually flagged duplicates — dedup_citations_add_manual","title":"This function performs additional deduplication with the additional of manually flagged duplicates — dedup_citations_add_manual","text":"function performs additional deduplication additional manually flagged duplicates","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/dedup_citations_add_manual.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function performs additional deduplication with the additional of manually flagged duplicates — dedup_citations_add_manual","text":"","code":"dedup_citations_add_manual(   unique_citations,   merge_citations = TRUE,   keep_source = NULL,   keep_label = NULL,   additional_pairs,   extra_merge_fields = NULL,   show_unknown_tags = TRUE )"},{"path":"https://camaradesuk.github.io/ASySD/reference/dedup_citations_add_manual.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function performs additional deduplication with the additional of manually flagged duplicates — dedup_citations_add_manual","text":"unique_citations dataframe containing citations automated deduplication merge_citations Logical value. want merge matching citations? keep_source Character vector. Selected citation source preferentially retain dataset unique record keep_label Selected citation label preferentially retain dataset unique record additional_pairs dataframe citations manual pairs, subset manual pairs export. result column included, value match merged extra_merge_fields Add additional fields merge, output similar label, source, record_id columns commas merged value show_unknown_tags label, source, merged field missing, want show \"unknown\"?","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/dedup_citations_add_manual.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"This function performs additional deduplication with the additional of manually flagged duplicates — dedup_citations_add_manual","text":"Unique citations post manual deduplication","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/dedup_citations_add_manual.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"This function performs additional deduplication with the additional of manually flagged duplicates — dedup_citations_add_manual","text":"","code":"# Perform deduplication result <- dedup_citations(citations_df, keep_source=\"Embase\") #> formatting data... #> identifying potential duplicates... #> identified duplicates! #> flagging potential pairs for manual dedup... #> Joining with `by = join_by(duplicate_id.x, duplicate_id.y)` #> 1001 citations loaded... #> 392 duplicate citations removed... #> 609 unique citations remaining!  # View unique citations res_unique <- result$unique head(result$manual_dedup) #> # A tibble: 6 × 41 #>   author1  author2 author title1 title2 title abstract1 abstract2 abstract year1 #>   <chr>    <chr>    <dbl> <chr>  <chr>  <dbl> <chr>     <chr>        <dbl> <chr> #> 1 Oliveir… de Oli…  0.839 Effec… Effec… 0.888 \"OBJECTI… \"Objecti…    0.933 2009  #> 2 Zou T.,… Yan H.…  0.638 Effec… Effec… 0.847 \"Introdu… \"Introdu…    0.813 2010  #> 3 Koenig … Abotal…  0.565 Focus… Focus… 0.907 \"Skeleta… \"Vitamin…    0.775 2010  #> 4 Davaria… Koenig…  0.594 Focus… Focus… 0.903 \"Reducin… \"Skeleta…    0.789 2010  #> 5 Davaria… Abotal…  0.646 Focus… Focus… 0.909 \"Reducin… \"Vitamin…    0.781 2010  #> 6 Liu X. … Liu X.…  0.937 Effec… Effec… 0.835 \"In a mo… \"The eff…    0.769 1997  #> # ℹ 31 more variables: year2 <chr>, year <dbl>, number1 <chr>, number2 <chr>, #> #   number <dbl>, pages1 <chr>, pages2 <chr>, pages <dbl>, volume1 <chr>, #> #   volume2 <chr>, volume <dbl>, journal1 <chr>, journal2 <chr>, journal <dbl>, #> #   isbn <dbl>, isbn1 <chr>, isbn2 <chr>, doi1 <chr>, doi2 <chr>, doi <dbl>, #> #   record_id1 <chr>, record_id2 <chr>, label1 <chr>, label2 <chr>, #> #   source1 <chr>, source2 <chr>, duplicate_id.x <chr>, duplicate_id.y <chr>, #> #   match <lgl>, min_id <chr>, max_id <chr>  true_dups <- result$manual_dedup[1:5,] # or equivalently true_dups <- result$manual_dedup  # You can also use a Shiny interface to review the potential duplicates # true_dups <- manual_dedup_shiny(result$manual_dedup)  final_result <- dedup_citations_add_manual(res_unique, additional_pairs = true_dups) #> Joining with `by = join_by(record_id)`"},{"path":"https://camaradesuk.github.io/ASySD/reference/field_codes_pubmed.html","id":null,"dir":"Reference","previous_headings":"","what":"Field conversion codes for pubmed imports — field_codes_pubmed","title":"Field conversion codes for pubmed imports — field_codes_pubmed","text":"Field conversion codes pubmed imports","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/field_codes_pubmed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Field conversion codes for pubmed imports — field_codes_pubmed","text":"","code":"field_codes_pubmed"},{"path":"https://camaradesuk.github.io/ASySD/reference/field_codes_pubmed.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Field conversion codes for pubmed imports — field_codes_pubmed","text":"object class spec_tbl_df (inherits tbl_df, tbl, data.frame) 78 rows 4 columns.","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/field_codes_pubmed.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Field conversion codes for pubmed imports — field_codes_pubmed","text":"Kaitlyn Hair kaitlyn.hair@ed.ac.uk","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/field_codes_wos.html","id":null,"dir":"Reference","previous_headings":"","what":"Field conversion codes for Web of Science imports — field_codes_wos","title":"Field conversion codes for Web of Science imports — field_codes_wos","text":"Field conversion codes Web Science imports","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/field_codes_wos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Field conversion codes for Web of Science imports — field_codes_wos","text":"","code":"field_codes_wos"},{"path":"https://camaradesuk.github.io/ASySD/reference/field_codes_wos.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Field conversion codes for Web of Science imports — field_codes_wos","text":"object class spec_tbl_df (inherits tbl_df, tbl, data.frame) 14 rows 4 columns.","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/field_codes_wos.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Field conversion codes for Web of Science imports — field_codes_wos","text":"Kaitlyn Hair kaitlyn.hair@ed.ac.uk","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/load_multi_search.html","id":null,"dir":"Reference","previous_headings":"","what":"Load in citations for deduplication — load_multi_search","title":"Load in citations for deduplication — load_multi_search","text":"function loads citation file within shiny app","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/load_multi_search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load in citations for deduplication — load_multi_search","text":"","code":"load_multi_search(paths, names, method)"},{"path":"https://camaradesuk.github.io/ASySD/reference/load_multi_search.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load in citations for deduplication — load_multi_search","text":"paths Relative paths citations file files names File names input file files method Import method","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/load_multi_search.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load in citations for deduplication — load_multi_search","text":"dataframe loaded citations.","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/load_search.html","id":null,"dir":"Reference","previous_headings":"","what":"Load in citations for deduplication — load_search","title":"Load in citations for deduplication — load_search","text":"function loads citations file using specified import method. method provided, defaults one based file extension. Supported methods: \"endnote\", \"csv\", \"txt\", \"bib\", \"zotero_csv\", \"ris\".","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/load_search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load in citations for deduplication — load_search","text":"","code":"load_search(path, method = NULL)"},{"path":"https://camaradesuk.github.io/ASySD/reference/load_search.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load in citations for deduplication — load_search","text":"path File path(s) one citations file(s). one file passed, file name added source field distinguish citations came method Import method. Valid options \"endnote\", \"csv\", \"txt\", \"bib\", \"zotero_csv\", \"ris\". provided, method inferred file extension.","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/load_search.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load in citations for deduplication — load_search","text":"dataframe citations.","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/manual_dedup_shiny.html","id":null,"dir":"Reference","previous_headings":"","what":"A Shiny interface to review potential duplicates — manual_dedup_shiny","title":"A Shiny interface to review potential duplicates — manual_dedup_shiny","text":"dedup_citations() can return potential duplicates manual review. function takes potential duplicates provides Shiny interface review select deduplicated. output can passed dedup_citations_add_manual() complete deduplication, used call function manual review yet complete.","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/manual_dedup_shiny.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A Shiny interface to review potential duplicates — manual_dedup_shiny","text":"","code":"manual_dedup_shiny(df, cols = names(df))"},{"path":"https://camaradesuk.github.io/ASySD/reference/manual_dedup_shiny.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A Shiny interface to review potential duplicates — manual_dedup_shiny","text":"df dataframe containing potential duplicate entries, typically returned dedup_citations(). cols character vector column names display review process. default, uses columns df.","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/manual_dedup_shiny.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A Shiny interface to review potential duplicates — manual_dedup_shiny","text":"dataframe updated result column, indicating whether entry duplicate (\"match\") (\"no_match\"). can passed dedup_citations_add_manual() completing deduplication process. dataframe result column indicating whether entry constitutes duplicate - passed dedup_citations_add_manual()","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/manual_dedup_shiny.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A Shiny interface to review potential duplicates — manual_dedup_shiny","text":"","code":"if (FALSE) { # interactive()  # Perform deduplication result <- dedup_citations(citations_df, keep_source=\"Embase\")  # Manually review potential duplicates manual_review <- manual_dedup_shiny(result$manual_dedup)  # Complete deduplication final_result <- dedup_citations_add_manual(result$unique, additional_pairs = manual_review) }"},{"path":"https://camaradesuk.github.io/ASySD/reference/merge_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"This function generates a duplicate ID for sets of matching citations — merge_metadata","title":"This function generates a duplicate ID for sets of matching citations — merge_metadata","text":"function generates duplicate ID sets matching citations","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/merge_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function generates a duplicate ID for sets of matching citations — merge_metadata","text":"","code":"merge_metadata(matched_pairs_with_ids, extra_merge_fields)"},{"path":"https://camaradesuk.github.io/ASySD/reference/merge_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function generates a duplicate ID for sets of matching citations — merge_metadata","text":"matched_pairs_with_ids citation data duplicate ids extra_merge_fields Add additional fields merge, output similar label, source, record_id columns commas merged value","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/merge_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"This function generates a duplicate ID for sets of matching citations — merge_metadata","text":"Dataframe formatted citation data duplicate id","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/write_citations.html","id":null,"dir":"Reference","previous_headings":"","what":"This function writes citation data to disk in different formats — write_citations","title":"This function writes citation data to disk in different formats — write_citations","text":"function writes citation data disk different formats","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/write_citations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function writes citation data to disk in different formats — write_citations","text":"","code":"write_citations(citations, type = c(\"ris\", \"txt\", \"csv\", \"bib\"), filename)"},{"path":"https://camaradesuk.github.io/ASySD/reference/write_citations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function writes citation data to disk in different formats — write_citations","text":"citations data frame containing citations - usually post-deduplication type export type filename output file name","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/write_citations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"This function writes citation data to disk in different formats — write_citations","text":"file export","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/write_citations_app.html","id":null,"dir":"Reference","previous_headings":"","what":"This function writes citation data to disk in different formats — write_citations_app","title":"This function writes citation data to disk in different formats — write_citations_app","text":"function writes citation data disk different formats","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/write_citations_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function writes citation data to disk in different formats — write_citations_app","text":"","code":"write_citations_app(citations, type = c(\"ris\", \"txt\", \"csv\", \"bib\"), filename)"},{"path":"https://camaradesuk.github.io/ASySD/reference/write_citations_app.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function writes citation data to disk in different formats — write_citations_app","text":"citations dataframe containing citations - usually post-deduplication type export type filename output file name","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/write_citations_app.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"This function writes citation data to disk in different formats — write_citations_app","text":"file export","code":""},{"path":"https://camaradesuk.github.io/ASySD/reference/write_citations_app.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"This function writes citation data to disk in different formats — write_citations_app","text":"","code":"# Create sample citations dataframe citations <- data.frame(   author = c(\"Author1\", \"Author2\"),   year = c(2000, 2001),   title = c(\"Title 1\", \"Title 2\"),   journal = c(\"Journal A\", \"Journal B\"),   doi = c(\"doi1\", \"doi2\"),   pages = c(\"1-10\", \"20-30\"),   volume = c(\"Vol 1\", \"Vol 2\"),   number = c(\"Issue 1\", \"Issue 2\"),   abstract = c(\"Abstract 1\", \"Abstract 2\"),   isbn = c(\"123456789\", \"987654321\"),   file_name = c(\"\", \"\"),   record_id = c(1, 2),   duplicate_id = c(1, 2),   label = c(\"Label A\", \"Label B\"),   source = c(\"Source A\", \"Source B\"),   stringsAsFactors = FALSE )  # Example usage for exporting to txt format write_citations_app(citations, type = \"txt\", filename = \"citations.txt\") unlink(\"citations.txt\")"},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-045","dir":"Changelog","previous_headings":"","what":"ASySD 0.4.5","title":"ASySD 0.4.5","text":"Fixed bug manual dedup preventing removal TRUE duplicates (marked humans)","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-044","dir":"Changelog","previous_headings":"","what":"ASySD 0.4.4","title":"ASySD 0.4.4","text":"Fixed issue RIS import replaced synthesisr RIS dependency","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-043","dir":"Changelog","previous_headings":"","what":"ASySD 0.4.3","title":"ASySD 0.4.3","text":"Fixed bug manual deduplication allow users proceed every article reviewed","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-042","dir":"Changelog","previous_headings":"","what":"ASySD 0.4.2","title":"ASySD 0.4.2","text":"Fixed issue app incorrect use mutate RIS export Fixed issue app redundant arguments old functions Updated page app","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-041","dir":"Changelog","previous_headings":"","what":"ASySD 0.4.1","title":"ASySD 0.4.1","text":"Improvements load_search() allow multiple files without need explicity add method argument","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-040","dir":"Changelog","previous_headings":"","what":"ASySD 0.4.0","title":"ASySD 0.4.0","text":"Addition manual_dedup_shiny() function aid manual deduplication process package","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-035","dir":"Changelog","previous_headings":"","what":"ASySD 0.3.5","title":"ASySD 0.3.5","text":"Simplification merge functions deduplication process Bug fix extra_merge_fields functionality prevented correct merging record_ids New unit test manual deduplication","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-034","dir":"Changelog","previous_headings":"","what":"ASySD 0.3.4","title":"ASySD 0.3.4","text":"Simplification deduplication functions - broken smaller functions called Added functionality batch deduplication + accompanying vignette Automatically detecting whether shiny app use (deduplication functions) removing redundant arguments Improvements documentation examples","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-033","dir":"Changelog","previous_headings":"","what":"ASySD 0.3.3","title":"ASySD 0.3.3","text":"Improvements export metadata - now retains URLs app export Improved error handling 0 duplicates present Additional unit tests package stability","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-032","dir":"Changelog","previous_headings":"","what":"ASySD 0.3.2","title":"ASySD 0.3.2","text":"Bug fix RIS export Improved error handling manual deduplication (app)","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-031","dir":"Changelog","previous_headings":"","what":"ASySD 0.3.1","title":"ASySD 0.3.1","text":"Bug fix multi-search upload RIS","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-030","dir":"Changelog","previous_headings":"","what":"ASySD 0.3.0","title":"ASySD 0.3.0","text":"Streamlining merging / keep_one_unique functions adapt new duplicate id generation logic (igraph) Ensuring extra_merge_fields supported throughout merging manual dedup Improvements bib imports via databases (bibliometrix data import required) Removing documentation internal functions Simplifying removing redundant functions","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-021","dir":"Changelog","previous_headings":"","what":"ASySD 0.2.1","title":"ASySD 0.2.1","text":"Minor bug fix app logic Change wording generating unique ids (based row number row name) Adding shiny progress updates back ","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-020","dir":"Changelog","previous_headings":"","what":"ASySD 0.2.0","title":"ASySD 0.2.0","text":"Improvements documentation files (CRAN submission preparation) Changed default deduplication type merged Improved bib imports via bibliometrix field code conversions Improvements manual deduplication process - need go entire deduplication procedure Improvements merging process / duplicate_id selection building network matching records using graph theory (via igraph package) Added helper pop-ups Added flag symbols indicate pair citations flagged later review manual_dedup Bug fix selection logic selecting label / source keep Aesthetic changes (colour highlight tables changed align colour scheme)","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-012","dir":"Changelog","previous_headings":"","what":"ASySD 0.1.2","title":"ASySD 0.1.2","text":"Added new dedup_citations argument show_unknown_tags (logical) specify whether merged fields “unknown” elements sources / labels [TRUE] [FALSE] Put shiny alert redirect notice old RDedup web link Shiny app","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-011","dir":"Changelog","previous_headings":"","what":"ASySD 0.1.1","title":"ASySD 0.1.1","text":"Added shiny_progress argument allow loading bar shiny app Bug fixes multiple uploads shiny app Bug fixes RIS import","code":""},{"path":"https://camaradesuk.github.io/ASySD/news/index.html","id":"asysd-010","dir":"Changelog","previous_headings":"","what":"ASySD 0.1.0","title":"ASySD 0.1.0","text":"Added NEWS.md file track changes package. Bug fix parallel processing errors (windows OS) CRAN preparation - small fixes ensure CMD check pass Added multi-search loading functions shiny app Added additional import options load_search() functions, including RIS Added documentation (user guide page) shiny app Enhanced error handling user messages Improved unit tests package stability","code":""}]
